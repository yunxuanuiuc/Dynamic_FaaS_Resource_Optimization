{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b1e621",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import vowpalwabbit as vw\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7b6c20",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class optimizer():\n",
    "    def __init__(self,\n",
    "                 memory_list: list,\n",
    "                 optimization_objective: str,\n",
    "                 features: list,\n",
    "                 model_name: str,  \n",
    "                 model_path: str\n",
    "                ):\n",
    "        \"\"\"\n",
    "        this optimizer supports sequential learning (batched learning not supported). \n",
    "        observations will be fed in one after another to update the model.s\n",
    "        ------\n",
    "        memory_list: a sorted list of candidate memory sizes, in ascending order\n",
    "        optimization_objective: \"budget\", or \"time\". \n",
    "        --TODO: consider supporting weighted sum of different objectives in future\n",
    "        features: list of the contextual features that the optimizer will take into account when learning\n",
    "        model_path: the place where the model is stored at and can be loaded from\n",
    "        \"\"\"\n",
    "        self.memories = memory_list # TODO: transform candidates into integers from 1 to N\n",
    "        self.mem2action = {self.memories[i]: i+1 for i in range(len(self.memories))}\n",
    "        self.action2mem = {i+1: self.memories[i] for i in range(len(self.memories))}\n",
    "        \n",
    "        self.n_actions = len(self.memories)\n",
    "        self.minimizing_objective = optimization_objective\n",
    "        self.features = features\n",
    "        self.model_name = model_name\n",
    "        self.model_path = model_path\n",
    "\n",
    "        if os.path.exists(os.path.join(self.model_path, self.model_name)):\n",
    "            self.model = vw\n",
    "        else:\n",
    "            self.model = vw.Workspace(f\"--cb_explore {self.n_actions} --epsilon 0.1\", quiet=True, enable_logging=True) \n",
    "            # TODO: add other hyperparameters here\n",
    "    \n",
    "        \n",
    "    def convert_to_vw_format(self,\n",
    "                             request, \n",
    "                             feature_keys: list,\n",
    "                             predict_mode = False,\n",
    "                             mem_key: str = None, \n",
    "                             cost_key:str = None,\n",
    "                             prob_key: str = None):\n",
    "        \"\"\"\n",
    "        Convert the input request to vw-compatible format\n",
    "        ------\n",
    "        The request should contain the following input:\n",
    "            - action: memory size chosen\n",
    "            - objective function score: cost, or time\n",
    "            - probability: the probability that this action was chosen\n",
    "            - features: other features of this request\n",
    "        \"\"\"\n",
    "        if not predict_mode:\n",
    "            obs = (\n",
    "            str(self.mem2action[request[mem_key]])\n",
    "            + \":\"\n",
    "            + str(request[cost_key])\n",
    "            + \":\"\n",
    "            + str(request[prob_key])\n",
    "            + \" |\"\n",
    "        )\n",
    "        else:\n",
    "            obs = \"|\"\n",
    "        \n",
    "        for key in feature_keys:\n",
    "            obs += \" \" + str(request[key])\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def observe(self, \n",
    "                request, \n",
    "                feature_keys: list = [\"bytes\"],\n",
    "                mem_key: str = \"memory\", \n",
    "                cost_key:str = \"cost\",\n",
    "                prob_key: str = \"probability\"):\n",
    "        \"\"\"\n",
    "        given a trial which has an action, cost, probability of the action, and features, \n",
    "        learn the data and update the model\n",
    "        \"\"\"\n",
    "        self.model.learn(self.convert_to_vw_format(request, feature_keys, False, mem_key, cost_key, prob_key))\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_custom_pmf(pmf):\n",
    "        total = sum(pmf)\n",
    "        scale = 1 / total\n",
    "        pmf = [x * scale for x in pmf]\n",
    "        draw = random.random()\n",
    "        sum_prob = 0.0\n",
    "        for index, prob in enumerate(pmf):\n",
    "            sum_prob += prob\n",
    "            if sum_prob > draw:\n",
    "                return index, prob\n",
    "    \n",
    "    def recommend(self, \n",
    "                  request,\n",
    "                  feature_keys: list = [\"bytes\"]):\n",
    "        \"\"\"\n",
    "        given an incoming trail with certain features, recommend an memory\n",
    "        \"\"\"\n",
    "        rec_probabilities = self.model.predict(self.convert_to_vw_format(request, feature_keys, True))\n",
    "        index, prob = self.sample_custom_pmf(rec_probabilities)\n",
    "        return self.action2mem[index+1]\n",
    "        \n",
    "    def save_model_state(self):\n",
    "        \"\"\"\n",
    "        save the current model for future use\n",
    "        \"\"\"\n",
    "        self.model.save(f\"{os.path.join(self.model_path, self.model_name)}.model\")\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        load and continue to use current model.\n",
    "        \"\"\"\n",
    "        self.model = vw.Workspace(f\"{os.path.join(self.model_path, self.model_name)}.model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa83b1d-cdee-4f6f-b408-7413215d24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_sample1 = {\"memory\": 128,\n",
    "                   \"probability\": 0.5,\n",
    "                   \"cost\": 1, # 10ms\n",
    "                   \"bytes\": 11}\n",
    "request_sample2 = {\"memory\": 128,\n",
    "                   \"probability\": 0.5,\n",
    "                   \"cost\": 1, # 10ms\n",
    "                   \"bytes\": 10}\n",
    "request_sample3 = {\"memory\": 64,\n",
    "                   \"probability\": 0.5,\n",
    "                   \"cost\": 13, # 10ms\n",
    "                   \"bytes\": 11}\n",
    "request_sample4 = {\"memory\": 64,\n",
    "                   \"probability\": 0.5,\n",
    "                   \"cost\": 14, # 10ms\n",
    "                   \"bytes\": 13}\n",
    "request_sample5 = {\"memory\": 128,\n",
    "                   \"probability\": 0.5,\n",
    "                   \"cost\": 1, # 10ms\n",
    "                   \"bytes\": 13}\n",
    "request_sample6 = {\"memory\": 64,\n",
    "                   \"probability\": 0.5,\n",
    "                   \"cost\": 16, # 10ms\n",
    "                   \"bytes\": 13}\n",
    "requests = [request_sample1, request_sample2, request_sample3, request_sample4, request_sample5, request_sample6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defe924f-0bef-4e14-ab8f-6d7411c3610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_optimizer = optimizer(\n",
    "                    memory_list=[64, 128],\n",
    "                    optimization_objective=\"time\",\n",
    "                    features=[\"bytes\"],\n",
    "                    model_name=\"example\",  \n",
    "                    model_path=\"./model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d6228d-8122-4b0c-8458-120c27a25d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for request in requests:\n",
    "    example_optimizer.observe(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f776ba7-2631-4521-99eb-80054f7229c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_optimizer.recommend({\"bytes\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eaace4-b16a-4576-9ac3-6aa8afbd9486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
